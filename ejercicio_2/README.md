# Clasificador de Gestos - Piedra, Papel o Tijeras âœŠâœ‹âœŒï¸

## Trabajo PrÃ¡ctico - Redes Densas y Convolucionales 2025
**Tecnicatura Universitaria en Inteligencia Artificial**

### Profesores
* Moreyra, Matias
* Cocitto LÃ³pez, Bruno
* Moreyra, Facundo

### Integrantes
* Borgo Elgart, Iair (Legajo: B-6608/7)
* Flaibani, Marcela (Legajo: F-3793/1)
* Nardi, Albano (Legajo: N-1280/7)

## ğŸ“Œ DescripciÃ³n del Proyecto

Este proyecto implementa un sistema de clasificaciÃ³n de gestos de mano para el juego "Piedra, Papel o Tijeras" utilizando tÃ©cnicas de aprendizaje automÃ¡tico. Se emplea **MediaPipe** para la detecciÃ³n de puntos clave (landmarks) de la mano, y una red neuronal completamente conectada para clasificar el gesto mostrado por el usuario.

El desarrollo se organiza en tres scripts:

- `record-dataset.py`: Captura y guarda muestras de gestos usando la webcam.
- `train-gesture-classifier.py`: Entrena un modelo de red neuronal sobre los datos capturados.
- `rock-paper-scissors.py`: Clasifica gestos en tiempo real desde la cÃ¡mara.

---

## ğŸ“ Estructura del Proyecto

ejercicio_2/
â”œâ”€â”€ record-dataset.py
â”œâ”€â”€ train-gesture-classifier.py
â”œâ”€â”€ rock-paper-scissors.py
â”œâ”€â”€ rps_dataset_borgo.npy
â”œâ”€â”€ rps_dataset_flaibani.npy
â”œâ”€â”€ rps_dataset_flaibanii.npy
â”œâ”€â”€ rps_dataset_nardi.npy
â”œâ”€â”€ rps_dataset_nardii.npy
â”œâ”€â”€ rps_labels_borgo.npy
â”œâ”€â”€ rps_labels_flaibani.npy
â”œâ”€â”€ rps_labels_flaibanii.npy
â”œâ”€â”€ rps_labels_nardi.npy
â”œâ”€â”€ rps_labels_nardii.npy
â”œâ”€â”€ model5411param.h5
â”œâ”€â”€ graf_model_5411.png
â””â”€â”€ imagenes/
    â”œâ”€â”€ capturas_dataset/
    â””â”€â”€ pruebas_prediccion/


---

## ğŸ§° TecnologÃ­as Utilizadas

- Python 3.10+
- Python 3.12+
- [OpenCV](https://opencv.org/)
- [MediaPipe](https://developers.google.com/mediapipe)
- [NumPy](https://numpy.org/)
- [TensorFlow / Keras](https://www.tensorflow.org/)
- [scikit-learn](https://scikit-learn.org/)
- [Matplotlib](https://matplotlib.org/)

---

## ğŸ“¦ Dataset

El dataset fue generado utilizando MediaPipe con python en la versiÃ³n "Python 3.10" ya que las posteriores presentaron problemas, extrayendo 21 puntos clave por mano, resultando en 42 coordenadas (x, y) por muestra.

- Se capturaron gestos de mÃºltiples personas.
- Se variaron posiciones, Ã¡ngulos y condiciones de luz.
- Las clases utilizadas fueron:
  - `0`: Piedra âœŠ
  - `1`: Papel âœ‹
  - `2`: Tijeras âœŒï¸

Las muestras estÃ¡n almacenadas en los archivos:

### Features:
- rps_dataset_borgo.npy
- rps_dataset_flaibani.npy
- rps_dataset_nardi.npy
- rps_dataset_flaibanii.npy
- rps_dataset_nardii.npy
- 
### Etiquetas:
- rps_labels_borgo.npy
- rps_labels_flaibani.npy
- rps_labels_nardi.npy
- rps_labels_flaibanii.npy
- rps_labels_nardii.npy
- 
---

## ğŸ§  Entrenamiento del Modelo

El modelo entrenado es una red neuronal densa con tres capas ocultas. Se utilizaron tÃ©cnicas de regularizaciÃ³n (dropout) y early stopping para evitar el sobreajuste.

- Arquitectura: fully connected con ReLU.
- OptimizaciÃ³n: Adam.
- MÃ©trica: Accuracy.
- Se guardÃ³ el modelo final como `model5411param.h5`.

---

## ğŸ§ª EvaluaciÃ³n

Durante las pruebas en tiempo real (`rock-paper-scissors.py`):

- Se utilizÃ³ la webcam para detectar gestos.
- Se aplicÃ³ un **umbral de confianza (0.7)** para validar predicciones.
- La predicciÃ³n aparece sobre el video si la confianza es suficiente.

Capturas de predicciones y dataset estÃ¡n disponibles en la carpeta `imagenes/`.
Captura de grÃ¡fica con curvas de aprendizaje disponible en 'graf_model_5411.png'

---

## âœ… Resultados

- El modelo logrÃ³ una precisiÃ³n validada mayor al **85%**.
- El rendimiento fue robusto ante variaciones de posiciÃ³n.
- La confianza de predicciÃ³n superÃ³ el 85% en la mayorÃ­a de las muestras bien enfocadas.

---

## ğŸ“ ConclusiÃ³n

> Pudimos integrar una herramienta de visiÃ³n por computadora como MediaPipe con redes neuronales densas, logrando buenos resultados en tiempo real.
>
> El modelo demostrÃ³ una gran capacidad de generalizaciÃ³n, lo cual atribuyo a la diversidad de datos recolectados: distintas manos, Ã¡ngulos y posiciones. Esto fue intencional desde el diseÃ±o, pensando en la escalabilidad del sistema y su posible adaptaciÃ³n a un entorno real.
>
> AdemÃ¡s, trabajar con un umbral de confianza fue Ãºtil para asegurar que el sistema no hiciera predicciones errÃ³neas cuando los gestos no eran claros.
>

---

## ğŸ“ CrÃ©ditos

Trabajo realizado para la materia **Aprendizaje AutomÃ¡tico 2**, correspondiente a la **Tecnicatura Universitaria en Inteligencia Artificial**.

---
